package main

import (
	"archive/zip"
	"bytes"
	"encoding/json"
	"fmt"
	"io"
	"log"
	"net/http"
	"os"
	"strings"

	"github.com/IBM/sarama"
)

type CVERecord struct {
	Containers struct {
		CNA struct {
			Affected []struct {
				Product  string `json:"product"`
				Vendor   string `json:"vendor"`
				Versions []struct {
					Status  string `json:"status"`
					Version string `json:"version"`
				} `json:"versions"`
			} `json:"affected"`
			Descriptions []struct {
				Lang  string `json:"lang"`
				Value string `json:"value"`
			} `json:"descriptions"`
			ProblemTypes []struct {
				Descriptions []struct {
					Description string `json:"description"`
					Lang        string `json:"lang"`
					Type        string `json:"type"`
				} `json:"descriptions"`
			} `json:"problemTypes"`
			ProviderMetadata struct {
				DateUpdated string `json:"dateUpdated"`
				OrgID       string `json:"orgId"`
				ShortName   string `json:"shortName"`
			} `json:"providerMetadata"`
			References []struct {
				Name string   `json:"name"`
				Tags []string `json:"tags"`
				URL  string   `json:"url"`
			} `json:"references"`
			XLegacyV4Record struct {
				CVEDataMeta struct {
					Assigner string `json:"ASSIGNER"`
					ID       string `json:"ID"`
					State    string `json:"STATE"`
				} `json:"CVE_data_meta"`
				Affects struct {
					Vendor struct {
						VendorData []struct {
							Product struct {
								ProductData []struct {
									ProductName string `json:"product_name"`
									Version     struct {
										VersionData []struct {
											VersionValue string `json:"version_value"`
										} `json:"version_data"`
									} `json:"version"`
								} `json:"product_data"`
							} `json:"product"`
							VendorName string `json:"vendor_name"`
						} `json:"vendor_data"`
					} `json:"vendor"`
				} `json:"affects"`
				DataFormat  string `json:"data_format"`
				DataType    string `json:"data_type"`
				DataVersion string `json:"data_version"`
				Description struct {
					DescriptionData []struct {
						Lang  string `json:"lang"`
						Value string `json:"value"`
					} `json:"description_data"`
				} `json:"description"`
				ProblemType struct {
					ProblemTypeData []struct {
						Description []struct {
							Lang  string `json:"lang"`
							Value string `json:"value"`
						} `json:"description"`
					} `json:"problemtype_data"`
				} `json:"problemtype"`
				References struct {
					ReferenceData []struct {
						Name      string `json:"name"`
						Refsource string `json:"refsource"`
						URL       string `json:"url"`
					} `json:"reference_data"`
				} `json:"references"`
			} `json:"x_legacyV4Record"`
		} `json:"cna"`
	} `json:"containers"`
	CveMetadata struct {
		AssignerOrgID     string `json:"assignerOrgId"`
		AssignerShortName string `json:"assignerShortName"`
		CveID             string `json:"cveId"`
		DatePublished     string `json:"datePublished"`
		DateReserved      string `json:"dateReserved"`
		DateUpdated       string `json:"dateUpdated"`
		State             string `json:"state"`
	} `json:"cveMetadata"`
	DataType    string `json:"dataType"`
	DataVersion string `json:"dataVersion"`
}

func main() {
	if len(os.Args) != 3 {
		fmt.Println("Usage: processor <delta_zip_url> <tag_name>")
		os.Exit(1)
	}

	deltaZipURL := os.Args[1]
	tagName := os.Args[2]

	log.Printf("Starting processing for delta_zip_url: %s, tag_name: %s", deltaZipURL, tagName)

	// Process CVE data
	cveData, err := processCVEData(deltaZipURL, tagName)
	if err != nil {
		log.Fatalf("Error processing CVE data: %v", err)
	}

	log.Println("Successfully processed CVE data")

	// Send to Kafka
	if err := sendToKafka(cveData); err != nil {
		log.Fatalf("Error sending to Kafka: %v", err)
	}

	log.Printf("Successfully processed and sent CVE data for release %s", tagName)
}

func processCVEData(deltaZipURL, tagName string) ([]CVERecord, error) {
	log.Printf("Downloading delta zip from URL: %s", deltaZipURL)
	resp, err := http.Get(deltaZipURL)
	if err != nil {
		return nil, fmt.Errorf("error downloading delta zip: %v", err)
	}
	defer resp.Body.Close()

	log.Println("Successfully downloaded delta zip")

	body, err := io.ReadAll(resp.Body)
	if err != nil {
		return nil, fmt.Errorf("error reading response body: %v", err)
	}

	log.Println("Successfully read response body")

	zipReader, err := zip.NewReader(bytes.NewReader(body), int64(len(body)))
	if err != nil {
		return nil, fmt.Errorf("error creating zip reader: %v", err)
	}

	log.Println("Successfully created zip reader")

	var processedRecords []CVERecord

	for _, zipFile := range zipReader.File {
		if strings.HasSuffix(zipFile.Name, ".json") {
			log.Printf("Processing JSON file: %s", zipFile.Name)
			records, err := processJSONFile(zipFile)
			if err != nil {
				return nil, fmt.Errorf("error processing JSON file %s: %v", zipFile.Name, err)
			}
			processedRecords = append(processedRecords, records...)
		}
	}

	log.Println("Successfully processed all JSON files in the zip")

	return processedRecords, nil
}

func processJSONFile(zipFile *zip.File) ([]CVERecord, error) {
	log.Printf("Opening JSON file: %s", zipFile.Name)
	fileReader, err := zipFile.Open()
	if err != nil {
		return nil, err
	}
	defer fileReader.Close()

	log.Printf("Successfully opened JSON file: %s", zipFile.Name)

	var cveRecords []CVERecord

	// Try to unmarshal as an array
	decoder := json.NewDecoder(fileReader)
	if err := decoder.Decode(&cveRecords); err != nil {
		// If unmarshaling as an array fails, reset and try as a single object
		log.Printf("Failed to decode as array, trying as single object: %v", err)
		fileReader.Close()
		fileReader, err = zipFile.Open()
		if err != nil {
			return nil, err
		}
		defer fileReader.Close()

		var singleRecord CVERecord
		decoder = json.NewDecoder(fileReader)
		if err := decoder.Decode(&singleRecord); err != nil {
			return nil, err
		}
		cveRecords = append(cveRecords, singleRecord)
	}

	log.Printf("Successfully decoded JSON file: %s", zipFile.Name)

	return cveRecords, nil
}

func sendToKafka(records []CVERecord) error {
	log.Println("Starting Kafka producer")
	config := sarama.NewConfig()
	config.Producer.Return.Successes = true

	brokers := strings.Split(os.Getenv("KAFKA_BROKERS"), ",")
	producer, err := sarama.NewSyncProducer(brokers, config)
	if err != nil {
		return fmt.Errorf("error creating Kafka producer: %v", err)
	}
	defer producer.Close()

	log.Println("Successfully created Kafka producer")

	for _, record := range records {
		data, err := json.Marshal(record)
		if err != nil {
			log.Printf("Error marshaling CVE record: %v", err)
			continue
		}

		msg := &sarama.ProducerMessage{
			Topic: os.Getenv("KAFKA_TOPIC"),
			Value: sarama.ByteEncoder(data),
		}

		log.Printf("Sending message to Kafka topic: %s", os.Getenv("KAFKA_TOPIC"))
		_, _, err = producer.SendMessage(msg)
		if err != nil {
			log.Printf("Error sending message to Kafka: %v", err)
		}
	}

	log.Println("Successfully sent all messages to Kafka")

	return nil
}
